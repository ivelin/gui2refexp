{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ivelin/gui2refexp/blob/main/gui_refexp_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWYDuD37BTOl"
      },
      "source": [
        "# GUI RefExp Notebook\n",
        "\n",
        "*   Based on LayoutML model suggested in this [IPA paper](https://github.com/debymf/ipa_probing)\n",
        "*   Initial fine tuning on Rico SCA dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LXnZTznBTOr"
      },
      "source": [
        "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Checkout source files from github repo\n",
        "![[ -d \"gui2refexp\" ]] || git clone https://github.com/ivelin/gui2refexp.git\n",
        "\n",
        "!cd gui2refexp && git pull\n",
        "\n",
        "!python --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HADV9ncQbmX-",
        "outputId": "d5f096e0-31f7-4245-aa6e-e87df79c45a0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n",
            "Python 3.8.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RTy5GI0fBTOr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f886ffb-c407-4d0e-a98c-a4581aacbea4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.8/dist-packages (from -r gui2refexp/requirements.txt (line 1)) (1.21.6)\n",
            "Requirement already satisfied: dynaconf>=2.2.3 in /usr/local/lib/python3.8/dist-packages (from -r gui2refexp/requirements.txt (line 2)) (3.1.11)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.8/dist-packages (from -r gui2refexp/requirements.txt (line 3)) (1.3.5)\n",
            "Requirement already satisfied: loguru>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from -r gui2refexp/requirements.txt (line 4)) (0.6.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (from -r gui2refexp/requirements.txt (line 5)) (4.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from -r gui2refexp/requirements.txt (line 8)) (4.64.1)\n",
            "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.8/dist-packages (from -r gui2refexp/requirements.txt (line 9)) (1.7.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from -r gui2refexp/requirements.txt (line 10)) (1.13.0+cu116)\n",
            "Requirement already satisfied: prefect==0.11.1 in /usr/local/lib/python3.8/dist-packages (from -r gui2refexp/requirements.txt (line 11)) (0.11.1)\n",
            "Requirement already satisfied: overrides==1.9 in /usr/local/lib/python3.8/dist-packages (from -r gui2refexp/requirements.txt (line 12)) (1.9)\n",
            "Requirement already satisfied: scikit_learn==0.24.2 in /usr/local/lib/python3.8/dist-packages (from -r gui2refexp/requirements.txt (line 13)) (0.24.2)\n",
            "Requirement already satisfied: urllib3>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (1.26.13)\n",
            "Requirement already satisfied: marshmallow<3.6.1,>=3.0.0b19 in /usr/local/lib/python3.8/dist-packages (from prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (3.6.0)\n",
            "Requirement already satisfied: click<8.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (7.1.2)\n",
            "Requirement already satisfied: pyyaml<5.4,>=3.13 in /usr/local/lib/python3.8/dist-packages (from prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (5.3.1)\n",
            "Requirement already satisfied: cloudpickle<1.5,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (1.4.1)\n",
            "Requirement already satisfied: python-box<5.0,>=3.4.4 in /usr/local/lib/python3.8/dist-packages (from prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (4.2.3)\n",
            "Requirement already satisfied: tabulate<1.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (0.8.10)\n",
            "Requirement already satisfied: pendulum<3.0,>=2.0.4 in /usr/local/lib/python3.8/dist-packages (from prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (2.1.2)\n",
            "Requirement already satisfied: mypy-extensions<1.0,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (0.4.3)\n",
            "Requirement already satisfied: python-slugify<5.0,>=1.2.6 in /usr/local/lib/python3.8/dist-packages (from prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (4.0.1)\n",
            "Requirement already satisfied: python-dateutil~=2.7 in /usr/local/lib/python3.8/dist-packages (from prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (2.8.2)\n",
            "Requirement already satisfied: distributed<3.0,>=1.26.1 in /usr/local/lib/python3.8/dist-packages (from prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (2.20.0)\n",
            "Requirement already satisfied: docker<5.0,>=3.4.1 in /usr/local/lib/python3.8/dist-packages (from prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (4.4.4)\n",
            "Requirement already satisfied: dask[bag]<3.0,>=0.19.3 in /usr/local/lib/python3.8/dist-packages (from prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (2.30.0)\n",
            "Requirement already satisfied: pytz>=2018.7 in /usr/local/lib/python3.8/dist-packages (from prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (2022.7)\n",
            "Requirement already satisfied: requests<3.0,>=2.20 in /usr/local/lib/python3.8/dist-packages (from prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (2.28.1)\n",
            "Requirement already satisfied: marshmallow-oneofschema<3.0,>=2.0.0b2 in /usr/local/lib/python3.8/dist-packages (from prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (2.1.0)\n",
            "Requirement already satisfied: croniter<1.0,>=0.3.24 in /usr/local/lib/python3.8/dist-packages (from prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (0.3.37)\n",
            "Requirement already satisfied: toml<1.0,>=0.9.4 in /usr/local/lib/python3.8/dist-packages (from prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (0.10.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit_learn==0.24.2->-r gui2refexp/requirements.txt (line 13)) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit_learn==0.24.2->-r gui2refexp/requirements.txt (line 13)) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers->-r gui2refexp/requirements.txt (line 5)) (3.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers->-r gui2refexp/requirements.txt (line 5)) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers->-r gui2refexp/requirements.txt (line 5)) (2022.6.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers->-r gui2refexp/requirements.txt (line 5)) (0.11.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers->-r gui2refexp/requirements.txt (line 5)) (0.13.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->-r gui2refexp/requirements.txt (line 10)) (4.4.0)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.8/dist-packages (from croniter<1.0,>=0.3.24->prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (5.5.0)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.8/dist-packages (from dask[bag]<3.0,>=0.19.3->prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (0.12.0)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from dask[bag]<3.0,>=0.19.3->prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (2022.11.0)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.8/dist-packages (from dask[bag]<3.0,>=0.19.3->prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from distributed<3.0,>=1.26.1->prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (1.0.4)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.8/dist-packages (from distributed<3.0,>=1.26.1->prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (2.2.0)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.8/dist-packages (from distributed<3.0,>=1.26.1->prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (5.4.8)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.8/dist-packages (from distributed<3.0,>=1.26.1->prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (2.4.0)\n",
            "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.8/dist-packages (from distributed<3.0,>=1.26.1->prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (6.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from distributed<3.0,>=1.26.1->prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (57.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from distributed<3.0,>=1.26.1->prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (1.7.0)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.8/dist-packages (from docker<5.0,>=3.4.1->prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (1.4.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from docker<5.0,>=3.4.1->prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers->-r gui2refexp/requirements.txt (line 5)) (3.0.9)\n",
            "Requirement already satisfied: pytzdata>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pendulum<3.0,>=2.0.4->prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (2020.1)\n",
            "Requirement already satisfied: ruamel.yaml in /usr/local/lib/python3.8/dist-packages (from python-box<5.0,>=3.4.4->prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (0.17.21)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify<5.0,>=1.2.6->prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.20->prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.20->prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.20->prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (2022.12.7)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.8/dist-packages (from partd>=0.3.10->dask[bag]<3.0,>=0.19.3->prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (1.0.0)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.8/dist-packages (from zict>=0.1.3->distributed<3.0,>=1.26.1->prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (1.0.1)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.6 in /usr/local/lib/python3.8/dist-packages (from ruamel.yaml->python-box<5.0,>=3.4.4->prefect==0.11.1->-r gui2refexp/requirements.txt (line 11)) (0.2.7)\n"
          ]
        }
      ],
      "source": [
        "!#@title Install third party libs\n",
        "!pip install -r gui2refexp/requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show prefect\n",
        "\n",
        "import prefect\n",
        "\n",
        "import prefect.engine as e\n",
        "\n",
        "help(e)\n",
        "dir(e)"
      ],
      "metadata": {
        "id": "Iu9BDkGGCcaX",
        "outputId": "bf3687c2-625b-4813-9882-70cb6e0e63b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: prefect\n",
            "Version: 0.11.1\n",
            "Summary: The Prefect Core automation and scheduling engine.\n",
            "Home-page: https://www.github.com/PrefectHQ/prefect\n",
            "Author: Prefect Technologies, Inc.\n",
            "Author-email: help@prefect.io\n",
            "License: Apache License 2.0\n",
            "Location: /usr/local/lib/python3.8/dist-packages\n",
            "Requires: click, cloudpickle, croniter, dask, distributed, docker, marshmallow, marshmallow-oneofschema, mypy-extensions, pendulum, python-box, python-dateutil, python-slugify, pytz, pyyaml, requests, tabulate, toml, urllib3\n",
            "Required-by: \n",
            "Help on module prefect.engine in prefect:\n",
            "\n",
            "NAME\n",
            "    prefect.engine - Client-side execution and orchestration of flows and tasks.\n",
            "\n",
            "DESCRIPTION\n",
            "    Engine process overview\n",
            "    \n",
            "    - The flow or task is called by the user.\n",
            "        See `Flow.__call__`, `Task.__call__`\n",
            "    \n",
            "    - A synchronous engine function acts as an entrypoint to the async engine.\n",
            "        See `enter_flow_run_engine`, `enter_task_run_engine`\n",
            "    \n",
            "    - The async engine creates a run via the API and prepares for execution of user-code.\n",
            "        See `begin_flow_run`, `begin_task_run`\n",
            "    \n",
            "    - The run is orchestrated through states, calling the user's function as necessary.\n",
            "        See `orchestrate_flow_run`, `orchestrate_task_run`\n",
            "\n",
            "FUNCTIONS\n",
            "    async begin_flow_run(flow: prefect.flows.Flow, flow_run: prefect.client.schemas.FlowRun, parameters: Dict[str, Any], client: prefect.client.orion.OrionClient) -> prefect.client.schemas.State\n",
            "        Begins execution of a flow run; blocks until completion of the flow run\n",
            "        \n",
            "        - Starts a task runner\n",
            "        - Determines the result storage block to use\n",
            "        - Orchestrates the flow run (runs the user-function and generates tasks)\n",
            "        - Waits for tasks to complete / shutsdown the task runner\n",
            "        - Sets a terminal state for the flow run\n",
            "        \n",
            "        Note that the `flow_run` contains a `parameters` attribute which is the serialized\n",
            "        parameters sent to the backend while the `parameters` argument here should be the\n",
            "        deserialized and validated dictionary of python objects.\n",
            "        \n",
            "        Returns:\n",
            "            The final state of the run\n",
            "    \n",
            "    async begin_task_map(task: prefect.tasks.Task, flow_run_context: prefect.context.FlowRunContext, parameters: Dict[str, Any], wait_for: Union[Iterable[prefect.futures.PrefectFuture], NoneType], return_type: Literal['future', 'state', 'result'], task_runner: Union[prefect.task_runners.BaseTaskRunner, NoneType]) -> List[Union[prefect.futures.PrefectFuture, Awaitable[prefect.futures.PrefectFuture]]]\n",
            "        Async entrypoint for task mapping\n",
            "    \n",
            "    async begin_task_run(task: prefect.tasks.Task, task_run: prefect.client.schemas.TaskRun, parameters: Dict[str, Any], wait_for: Union[Iterable[prefect.futures.PrefectFuture], NoneType], result_factory: prefect.results.ResultFactory, log_prints: bool, settings: prefect.context.SettingsContext)\n",
            "        Entrypoint for task run execution.\n",
            "        \n",
            "        This function is intended for submission to the task runner.\n",
            "        \n",
            "        This method may be called from a worker so we ensure the settings context has been\n",
            "        entered. For example, with a runner that is executing tasks in the same event loop,\n",
            "        we will likely not enter the context again because the current context already\n",
            "        matches:\n",
            "        \n",
            "        main thread:\n",
            "        --> Flow called with settings A\n",
            "        --> `begin_task_run` executes same event loop\n",
            "        --> Profile A matches and is not entered again\n",
            "        \n",
            "        However, with execution on a remote environment, we are going to need to ensure the\n",
            "        settings for the task run are respected by entering the context:\n",
            "        \n",
            "        main thread:\n",
            "        --> Flow called with settings A\n",
            "        --> `begin_task_run` is scheduled on a remote worker, settings A is serialized\n",
            "        remote worker:\n",
            "        --> Remote worker imports Prefect (may not occur)\n",
            "        --> Global settings is loaded with default settings\n",
            "        --> `begin_task_run` executes on a different event loop than the flow\n",
            "        --> Current settings is not set or does not match, settings A is entered\n",
            "    \n",
            "    async collect_task_run_inputs(expr: Any, max_depth: int = -1) -> Set[prefect.orion.schemas.core.TaskRunInput]\n",
            "        This function recurses through an expression to generate a set of any discernable\n",
            "        task run inputs it finds in the data structure. It produces a set of all inputs\n",
            "        found.\n",
            "        \n",
            "        Example:\n",
            "            >>> task_inputs = {\n",
            "            >>>    k: await collect_task_run_inputs(v) for k, v in parameters.items()\n",
            "            >>> }\n",
            "    \n",
            "    async create_and_begin_subflow_run(flow: prefect.flows.Flow, parameters: Dict[str, Any], wait_for: Union[Iterable[prefect.futures.PrefectFuture], NoneType], return_type: Literal['future', 'state', 'result'], client: prefect.client.orion.OrionClient) -> Any\n",
            "        Async entrypoint for flows calls within a flow run\n",
            "        \n",
            "        Subflows differ from parent flows in that they\n",
            "        - Resolve futures in passed parameters into values\n",
            "        - Create a dummy task for representation in the parent flow\n",
            "        - Retrieve default result storage from the parent flow rather than the server\n",
            "        \n",
            "        Returns:\n",
            "            The final state of the run\n",
            "    \n",
            "    async create_task_run(task: prefect.tasks.Task, name: str, flow_run_context: prefect.context.FlowRunContext, parameters: Dict[str, Any], dynamic_key: str, wait_for: Union[Iterable[prefect.futures.PrefectFuture], NoneType], extra_task_inputs: Dict[str, Set[prefect.orion.schemas.core.TaskRunInput]]) -> prefect.client.schemas.TaskRun\n",
            "    \n",
            "    async create_task_run_future(task: prefect.tasks.Task, flow_run_context: prefect.context.FlowRunContext, parameters: Dict[str, Any], wait_for: Union[Iterable[prefect.futures.PrefectFuture], NoneType], task_runner: Union[prefect.task_runners.BaseTaskRunner, NoneType], extra_task_inputs: Dict[str, Set[prefect.orion.schemas.core.TaskRunInput]]) -> prefect.futures.PrefectFuture\n",
            "    \n",
            "    async create_task_run_then_submit(task: prefect.tasks.Task, task_run_name: str, task_run_dynamic_key: str, future: prefect.futures.PrefectFuture, flow_run_context: prefect.context.FlowRunContext, parameters: Dict[str, Any], wait_for: Union[Iterable[prefect.futures.PrefectFuture], NoneType], task_runner: prefect.task_runners.BaseTaskRunner, extra_task_inputs: Dict[str, Set[prefect.orion.schemas.core.TaskRunInput]]) -> None\n",
            "    \n",
            "    async create_then_begin_flow_run(flow: prefect.flows.Flow, parameters: Dict[str, Any], wait_for: Union[Iterable[prefect.futures.PrefectFuture], NoneType], return_type: Literal['future', 'state', 'result'], client: prefect.client.orion.OrionClient) -> Any\n",
            "        Async entrypoint for flow calls\n",
            "        \n",
            "        Creates the flow run in the backend, then enters the main flow run engine.\n",
            "    \n",
            "    enter_flow_run_engine_from_flow_call(flow: prefect.flows.Flow, parameters: Dict[str, Any], wait_for: Union[Iterable[prefect.futures.PrefectFuture], NoneType], return_type: Literal['future', 'state', 'result']) -> Union[prefect.client.schemas.State, Awaitable[prefect.client.schemas.State]]\n",
            "        Sync entrypoint for flow calls.\n",
            "        \n",
            "        This function does the heavy lifting of ensuring we can get into an async context\n",
            "        for flow run execution with minimal overhead.\n",
            "    \n",
            "    enter_flow_run_engine_from_subprocess(flow_run_id: uuid.UUID) -> prefect.client.schemas.State\n",
            "        Sync entrypoint for flow runs that have been submitted for execution by an agent\n",
            "        \n",
            "        Differs from `enter_flow_run_engine_from_flow_call` in that we have a flow run id\n",
            "        but not a flow object. The flow must be retrieved before execution can begin.\n",
            "        Additionally, this assumes that the caller is always in a context without an event\n",
            "        loop as this should be called from a fresh process.\n",
            "    \n",
            "    enter_task_run_engine(task: prefect.tasks.Task, parameters: Dict[str, Any], wait_for: Union[Iterable[prefect.futures.PrefectFuture], NoneType], return_type: Literal['future', 'state', 'result'], task_runner: Union[prefect.task_runners.BaseTaskRunner, NoneType], mapped: bool) -> Union[prefect.futures.PrefectFuture, Awaitable[prefect.futures.PrefectFuture]]\n",
            "        Sync entrypoint for task calls\n",
            "    \n",
            "    get_state_for_result(obj: Any) -> Union[prefect.client.schemas.State, NoneType]\n",
            "        Get the state related to a result object.\n",
            "        \n",
            "        `link_state_to_result` must have been called first.\n",
            "    \n",
            "    async get_task_call_return_value(task: prefect.tasks.Task, flow_run_context: prefect.context.FlowRunContext, parameters: Dict[str, Any], wait_for: Union[Iterable[prefect.futures.PrefectFuture], NoneType], return_type: Literal['future', 'state', 'result'], task_runner: Union[prefect.task_runners.BaseTaskRunner, NoneType], extra_task_inputs: Union[Dict[str, Set[prefect.orion.schemas.core.TaskRunInput]], NoneType] = None)\n",
            "    \n",
            "    link_state_to_result(state: prefect.client.schemas.State, result: Any) -> None\n",
            "        Caches a link between a state and a result and its components using\n",
            "        the `id` of the components to map to the state. The cache is persisted to the\n",
            "        current flow run context since task relationships are limited to within a flow run.\n",
            "        \n",
            "        This allows dependency tracking to occur when results are passed around.\n",
            "        Note: Because `id` is used, we cannot cache links between singleton objects.\n",
            "        \n",
            "        We only cache the relationship between components 1-layer deep.\n",
            "        Example:\n",
            "            Given the result [1, [\"a\",\"b\"], (\"c\",)], the following elements will be\n",
            "            mapped to the state:\n",
            "            - [1, [\"a\",\"b\"], (\"c\",)]\n",
            "            - [\"a\",\"b\"]\n",
            "            - (\"c\",)\n",
            "        \n",
            "            Note: the int `1` will not be mapped to the state because it is a singleton.\n",
            "        \n",
            "        Other Notes:\n",
            "        We do not hash the result because:\n",
            "        - If changes are made to the object in the flow between task calls, we can still\n",
            "          track that they are related.\n",
            "        - Hashing can be expensive.\n",
            "        - Not all objects are hashable.\n",
            "        \n",
            "        We do not set an attribute, e.g. `__prefect_state__`, on the result because:\n",
            "        \n",
            "        - Mutating user's objects is dangerous.\n",
            "        - Unrelated equality comparisons can break unexpectedly.\n",
            "        - The field can be preserved on copy.\n",
            "        - We cannot set this attribute on Python built-ins.\n",
            "    \n",
            "    async orchestrate_flow_run(flow: prefect.flows.Flow, flow_run: prefect.client.schemas.FlowRun, parameters: Dict[str, Any], wait_for: Union[Iterable[prefect.futures.PrefectFuture], NoneType], interruptible: bool, client: prefect.client.orion.OrionClient, partial_flow_run_context: prefect.utilities.pydantic.PartialModel[prefect.context.FlowRunContext]) -> prefect.client.schemas.State\n",
            "        Executes a flow run.\n",
            "        \n",
            "        Note on flow timeouts:\n",
            "            Since async flows are run directly in the main event loop, timeout behavior will\n",
            "            match that described by anyio. If the flow is awaiting something, it will\n",
            "            immediately return; otherwise, the next time it awaits it will exit. Sync flows\n",
            "            are being task runner in a worker thread, which cannot be interrupted. The worker\n",
            "            thread will exit at the next task call. The worker thread also has access to the\n",
            "            status of the cancellation scope at `FlowRunContext.timeout_scope.cancel_called`\n",
            "            which allows it to raise a `TimeoutError` to respect the timeout.\n",
            "        \n",
            "        Returns:\n",
            "            The final state of the run\n",
            "    \n",
            "    async orchestrate_task_run(task: prefect.tasks.Task, task_run: prefect.client.schemas.TaskRun, parameters: Dict[str, Any], wait_for: Union[Iterable[prefect.futures.PrefectFuture], NoneType], result_factory: prefect.results.ResultFactory, log_prints: bool, interruptible: bool, client: prefect.client.orion.OrionClient) -> prefect.client.schemas.State\n",
            "        Execute a task run\n",
            "        \n",
            "        This function should be submitted to an task runner. We must construct the context\n",
            "        here instead of receiving it already populated since we may be in a new environment.\n",
            "        \n",
            "        Proposes a RUNNING state, then\n",
            "        - if accepted, the task user function will be run\n",
            "        - if rejected, the received state will be returned\n",
            "        \n",
            "        When the user function is run, the result will be used to determine a final state\n",
            "        - if an exception is encountered, it is trapped and stored in a FAILED state\n",
            "        - otherwise, `return_value_to_state` is used to determine the state\n",
            "        \n",
            "        If the final state is COMPLETED, we generate a cache key as specified by the task\n",
            "        \n",
            "        The final state is then proposed\n",
            "        - if accepted, this is the final state and will be returned\n",
            "        - if rejected and a new final state is provided, it will be returned\n",
            "        - if rejected and a non-final state is provided, we will attempt to enter a RUNNING\n",
            "            state again\n",
            "        \n",
            "        Returns:\n",
            "            The final state of the run\n",
            "    \n",
            "    pause_flow_run(flow_run_id: uuid.UUID = None, timeout: int = 300, poll_interval: int = 10, reschedule: bool = False, key: str = None)\n",
            "        Pauses the current flow run by stopping execution until resumed.\n",
            "        \n",
            "        When called within a flow run, execution will block and no downstream tasks will\n",
            "        run until the flow is resumed. Task runs that have already started will continue\n",
            "        running. A timeout parameter can be passed that will fail the flow run if it has not\n",
            "        been resumed within the specified time.\n",
            "        \n",
            "        Args:\n",
            "            flow_run_id: a flow run id. If supplied, this function will attempt to pause\n",
            "                the specified flow run outside of the flow run process. When paused, the\n",
            "                flow run will continue execution until the NEXT task is orchestrated, at\n",
            "                which point the flow will exit. Any tasks that have already started will\n",
            "                run until completion. When resumed, the flow run will be rescheduled to\n",
            "                finish execution. In order pause a flow run in this way, the flow needs to\n",
            "                have an associated deployment and results need to be configured with the\n",
            "                `persist_results` option.\n",
            "            timeout: the number of seconds to wait for the flow to be resumed before\n",
            "                failing. Defaults to 5 minutes (300 seconds). If the pause timeout exceeds\n",
            "                any configured flow-level timeout, the flow might fail even after resuming.\n",
            "            poll_interval: The number of seconds between checking whether the flow has been\n",
            "                resumed. Defaults to 10 seconds.\n",
            "            reschedule: Flag that will reschedule the flow run if resumed. Instead of\n",
            "                blocking execution, the flow will gracefully exit (with no result returned)\n",
            "                instead. To use this flag, a flow needs to have an associated deployment and\n",
            "                results need to be configured with the `persist_results` option.\n",
            "            key: An optional key to prevent calling pauses more than once. This defaults to\n",
            "                the number of pauses observed by the flow so far, and prevents pauses that\n",
            "                use the \"reschedule\" option from running the same pause twice. A custom key\n",
            "                can be supplied for custom pausing behavior.\n",
            "    \n",
            "    async propose_state(client: prefect.client.orion.OrionClient, state: prefect.client.schemas.State, force: bool = False, task_run_id: uuid.UUID = None, flow_run_id: uuid.UUID = None) -> prefect.client.schemas.State\n",
            "        Propose a new state for a flow run or task run, invoking Orion orchestration logic.\n",
            "        \n",
            "        If the proposed state is accepted, the provided `state` will be augmented with\n",
            "         details and returned.\n",
            "        \n",
            "        If the proposed state is rejected, a new state returned by the Orion API will be\n",
            "        returned.\n",
            "        \n",
            "        If the proposed state results in a WAIT instruction from the Orion API, the\n",
            "        function will sleep and attempt to propose the state again.\n",
            "        \n",
            "        If the proposed state results in an ABORT instruction from the Orion API, an\n",
            "        error will be raised.\n",
            "        \n",
            "        Args:\n",
            "            state: a new state for the task or flow run\n",
            "            task_run_id: an optional task run id, used when proposing task run states\n",
            "            flow_run_id: an optional flow run id, used when proposing flow run states\n",
            "        \n",
            "        Returns:\n",
            "            a [State model][prefect.orion.schemas.states] representation of the flow or task run\n",
            "                state\n",
            "        \n",
            "        Raises:\n",
            "            ValueError: if neither task_run_id or flow_run_id is provided\n",
            "            prefect.exceptions.Abort: if an ABORT instruction is received from\n",
            "                the Orion API\n",
            "    \n",
            "    report_flow_run_crashes(flow_run: prefect.client.schemas.FlowRun, client: prefect.client.orion.OrionClient)\n",
            "        Detect flow run crashes during this context and update the run to a proper final\n",
            "        state.\n",
            "        \n",
            "        This context _must_ reraise the exception to properly exit the run.\n",
            "    \n",
            "    report_task_run_crashes(task_run: prefect.client.schemas.TaskRun, client: prefect.client.orion.OrionClient)\n",
            "        Detect task run crashes during this context and update the run to a proper final\n",
            "        state.\n",
            "        \n",
            "        This context _must_ reraise the exception to properly exit the run.\n",
            "    \n",
            "    async resolve_inputs(parameters: Dict[str, Any], return_data: bool = True, max_depth: int = -1) -> Dict[str, Any]\n",
            "        Resolve any `Quote`, `PrefectFuture`, or `State` types nested in parameters into\n",
            "        data.\n",
            "        \n",
            "        Returns:\n",
            "            A copy of the parameters with resolved data\n",
            "        \n",
            "        Raises:\n",
            "            UpstreamTaskError: If any of the upstream states are not `COMPLETED`\n",
            "    \n",
            "    resume_flow_run(flow_run_id)\n",
            "        Resumes a paused flow.\n",
            "        \n",
            "        Args:\n",
            "            flow_run_id: the flow_run_id to resume\n",
            "    \n",
            "    async retrieve_flow_then_begin_flow_run(flow_run_id: uuid.UUID, client: prefect.client.orion.OrionClient) -> prefect.client.schemas.State\n",
            "        Async entrypoint for flow runs that have been submitted for execution by an agent\n",
            "        \n",
            "        - Retrieves the deployment information\n",
            "        - Loads the flow object using deployment information\n",
            "        - Updates the flow run version\n",
            "    \n",
            "    should_log_prints(flow_or_task: Union[prefect.flows.Flow, prefect.tasks.Task]) -> bool\n",
            "    \n",
            "    async submit_task_run(task: prefect.tasks.Task, future: prefect.futures.PrefectFuture, flow_run_context: prefect.context.FlowRunContext, parameters: Dict[str, Any], task_run: prefect.client.schemas.TaskRun, wait_for: Union[Iterable[prefect.futures.PrefectFuture], NoneType], task_runner: prefect.task_runners.BaseTaskRunner) -> prefect.futures.PrefectFuture\n",
            "    \n",
            "    async wait_for_task_runs_and_report_crashes(task_run_futures: Iterable[prefect.futures.PrefectFuture], client: prefect.client.orion.OrionClient) -> Literal[True]\n",
            "\n",
            "DATA\n",
            "    Any = typing.Any\n",
            "    Awaitable = typing.Awaitable\n",
            "    CONCURRENCY_MESSAGES = {TaskConcurrencyType.CONCURRENT: 'concurrently'...\n",
            "    Dict = typing.Dict\n",
            "    EngineReturnType = typing.Literal['future', 'state', 'result']\n",
            "    Iterable = typing.Iterable\n",
            "    List = typing.List\n",
            "    Literal = typing.Literal\n",
            "    Optional = typing.Optional\n",
            "    PREFECT_DEBUG_MODE = <PREFECT_DEBUG_MODE: bool>\n",
            "    PREFECT_LOGGING_LOG_PRINTS = <PREFECT_LOGGING_LOG_PRINTS: bool>\n",
            "    R = ~R\n",
            "    Set = typing.Set\n",
            "    UNTRACKABLE_TYPES = {<class 'ellipsis'>, <class 'bool'>, <class 'NoneT...\n",
            "    Union = typing.Union\n",
            "    engine_logger = <Logger prefect.engine (INFO)>\n",
            "\n",
            "FILE\n",
            "    /usr/local/lib/python3.8/dist-packages/prefect/engine.py\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Abort',\n",
              " 'Any',\n",
              " 'AsyncExitStack',\n",
              " 'Awaitable',\n",
              " 'BaseResult',\n",
              " 'BaseTaskRunner',\n",
              " 'CONCURRENCY_MESSAGES',\n",
              " 'Dict',\n",
              " 'EngineReturnType',\n",
              " 'Flow',\n",
              " 'FlowPauseTimeout',\n",
              " 'FlowRun',\n",
              " 'FlowRunContext',\n",
              " 'FlowRunFilter',\n",
              " 'FlowRunSort',\n",
              " 'Iterable',\n",
              " 'List',\n",
              " 'Literal',\n",
              " 'MappingLengthMismatch',\n",
              " 'MappingMissingIterable',\n",
              " 'NotPausedError',\n",
              " 'Optional',\n",
              " 'OrionClient',\n",
              " 'OrionHandler',\n",
              " 'PREFECT_DEBUG_MODE',\n",
              " 'PREFECT_LOGGING_LOG_PRINTS',\n",
              " 'PartialModel',\n",
              " 'Pause',\n",
              " 'Paused',\n",
              " 'PausedRun',\n",
              " 'Pending',\n",
              " 'PrefectFuture',\n",
              " 'PrefectObjectRegistry',\n",
              " 'Quote',\n",
              " 'R',\n",
              " 'ResultFactory',\n",
              " 'Running',\n",
              " 'Set',\n",
              " 'SetStateStatus',\n",
              " 'State',\n",
              " 'StateDetails',\n",
              " 'StateType',\n",
              " 'TagsContext',\n",
              " 'Task',\n",
              " 'TaskConcurrencyType',\n",
              " 'TaskRun',\n",
              " 'TaskRunContext',\n",
              " 'TaskRunInput',\n",
              " 'TaskRunResult',\n",
              " 'TypeVar',\n",
              " 'UNTRACKABLE_TYPES',\n",
              " 'UUID',\n",
              " 'Union',\n",
              " 'UpstreamTaskError',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__spec__',\n",
              " '_dynamic_key_for_task_run',\n",
              " '_in_process_pause',\n",
              " '_observed_flow_pauses',\n",
              " '_out_of_process_pause',\n",
              " 'allow_failure',\n",
              " 'anyio',\n",
              " 'asynccontextmanager',\n",
              " 'begin_flow_run',\n",
              " 'begin_task_map',\n",
              " 'begin_task_run',\n",
              " 'call_repr',\n",
              " 'collect_task_run_inputs',\n",
              " 'create_and_begin_subflow_run',\n",
              " 'create_task_run',\n",
              " 'create_task_run_future',\n",
              " 'create_task_run_then_submit',\n",
              " 'create_then_begin_flow_run',\n",
              " 'engine_logger',\n",
              " 'enter_flow_run_engine_from_flow_call',\n",
              " 'enter_flow_run_engine_from_subprocess',\n",
              " 'enter_task_run_engine',\n",
              " 'exception_to_crashed_state',\n",
              " 'exception_to_failed_state',\n",
              " 'flow_run_logger',\n",
              " 'gather',\n",
              " 'get_client',\n",
              " 'get_logger',\n",
              " 'get_run_logger',\n",
              " 'get_state_exception',\n",
              " 'get_state_for_result',\n",
              " 'get_task_call_return_value',\n",
              " 'in_async_main_thread',\n",
              " 'inject_client',\n",
              " 'isiterable',\n",
              " 'link_state_to_result',\n",
              " 'load_flow_from_flow_run',\n",
              " 'logging',\n",
              " 'nullcontext',\n",
              " 'orchestrate_flow_run',\n",
              " 'orchestrate_task_run',\n",
              " 'parameters_to_args_kwargs',\n",
              " 'partial',\n",
              " 'patch_print',\n",
              " 'pause_flow_run',\n",
              " 'pendulum',\n",
              " 'prefect',\n",
              " 'propose_state',\n",
              " 'report_flow_run_crashes',\n",
              " 'report_task_run_crashes',\n",
              " 'resolve_futures_to_states',\n",
              " 'resolve_inputs',\n",
              " 'resume_flow_run',\n",
              " 'retrieve_flow_then_begin_flow_run',\n",
              " 'return_value_to_state',\n",
              " 'run_async_from_worker_thread',\n",
              " 'run_sync_in_interruptible_worker_thread',\n",
              " 'run_sync_in_worker_thread',\n",
              " 'setup_logging',\n",
              " 'should_log_prints',\n",
              " 'stable_hash',\n",
              " 'start_blocking_portal',\n",
              " 'submit_task_run',\n",
              " 'sync_compatible',\n",
              " 'sys',\n",
              " 'task_run_logger',\n",
              " 'unmapped',\n",
              " 'uuid4',\n",
              " 'visit_collection',\n",
              " 'wait_for_task_runs_and_report_crashes']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Q4fPr4K5BTO6",
        "outputId": "ac319650-f4fd-45ee-c4b1-1af70038e164",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-051b140ba1f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mloguru\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mprefect\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mprefect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow_runner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFlowRunner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mprefect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLocalResult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlayout_ipa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets_parse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrico_sca\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPrepareRicoScaPair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'prefect.engine.flow_runner'; 'prefect.engine' is not a package",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "#@title Run LayoutML training flow for RefExp\n",
        "\n",
        "# !python -m  layout_ipa.flows.layout_lm.layout_lm_train_pair_classification\n",
        "\n",
        "\n",
        "import prefect\n",
        "from dynaconf import settings\n",
        "from loguru import logger\n",
        "from prefect import Flow, tags\n",
        "from prefect.engine.flow_runner import FlowRunner\n",
        "from prefect.engine.results import LocalResult\n",
        "from layout_ipa.tasks.datasets_parse.rico_sca import PrepareRicoScaPair\n",
        "# from layout_ipa.tasks.datasets_parse.pixel_help import PreparePixelHelpPair\n",
        "from layout_ipa.tasks.layout_lm.data_prep import PrepareLayoutLMPairTask\n",
        "from layout_ipa.tasks.layout_lm.model_pipeline import LayoutLMPair\n",
        "from sklearn.metrics import f1_score\n",
        "from layout_ipa.util.evaluation import pair_evaluation_2d\n",
        "\n",
        "prepare_rico_task = PrepareRicoScaPair()\n",
        "\n",
        "train_path = settings[\"rico_sca\"][\"train\"]\n",
        "dev_path = settings[\"rico_sca\"][\"dev\"]\n",
        "test_path = settings[\"rico_sca\"][\"test\"]\n",
        "\n",
        "## Uncomment this if you want to test for pixel_help\n",
        "#test_path = settings[\"pixel_help\"]\n",
        "\n",
        "prepare_rico_task = PrepareRicoScaPair()\n",
        "# prepare_pixel_help_task = PreparePixelHelpPair()\n",
        "prepare_rico_layout_lm_task = PrepareLayoutLMPairTask()\n",
        "layout_lm_trainer_task = LayoutLMPair()\n",
        "\n",
        "\n",
        "# Change the instruction type that you require here\n",
        "INSTRUCTION_TYPE = [0,1,2,3]\n",
        "#  where: 0 and 3 - Extractive\n",
        "#             1 - Absolute\n",
        "#             2 - Relative\n",
        "\n",
        "LAYOUT_LM_MODEL =  \"microsoft/layoutlmv2-base-uncased\"\n",
        "\n",
        "with Flow(\"Running the Transformers for Pair Classification\") as flow1:\n",
        "    with tags(\"train\"):\n",
        "        train_input = prepare_rico_task(train_path, type_instructions=INSTRUCTION_TYPE)\n",
        "        train_dataset = prepare_rico_layout_lm_task(train_input[\"data\"], tokenizer_model = LAYOUT_LM_MODEL)\n",
        "    with tags(\"dev\"):\n",
        "        dev_input = prepare_rico_task(dev_path, type_instructions=INSTRUCTION_TYPE)\n",
        "        dev_dataset = prepare_rico_layout_lm_task(dev_input[\"data\"], tokenizer_model = LAYOUT_LM_MODEL)\n",
        "    with tags(\"test\"):\n",
        "        test_input = prepare_rico_task(test_path, type_instructions=INSTRUCTION_TYPE)\n",
        "        # test_input = prepare_pixel_help_task(test_path)\n",
        "        test_dataset = prepare_rico_layout_lm_task(test_input[\"data\"], tokenizer_model = LAYOUT_LM_MODEL)\n",
        "    layout_lm_trainer_task(\n",
        "        train_dataset=train_dataset,\n",
        "        dev_dataset=dev_dataset,\n",
        "        test_dataset=test_dataset,\n",
        "        mapping_dev=dev_input[\"mapping\"],\n",
        "        mapping_test=test_input[\"mapping\"],\n",
        "        bert_model=LAYOUT_LM_MODEL,\n",
        "        task_name=\"layout_lm_pair_rico\",\n",
        "        output_dir=\"./cache/layout_lm_pair_rico/\",\n",
        "        mode=\"test\",\n",
        "        eval_fn=pair_evaluation_2d,\n",
        "    )\n",
        "\n",
        "\n",
        "FlowRunner(flow=flow1).run()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "What if my dataset isn't on the Hub?",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}